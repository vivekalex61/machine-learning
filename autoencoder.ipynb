{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeawoNcIcN_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "import pickle\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dicts = pickle.load(fo, encoding='latin1')\n",
        "    return dicts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moTVk-Hd186s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grayscale(im):\n",
        "    return im.reshape(im.shape[0], 3, 32, 32).mean(1).reshape(im.shape[0], -1)\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_image(image, shape=[32, 32], cmap = \"Greys_r\"):#function to convert decoder output to image\n",
        "    plt.imshow(image.reshape(shape), cmap=cmap,interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC2m0yzC2XFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data into memory\n",
        "data, labels = [], []\n",
        "## Loop over the b\n",
        "for i in range(1, 6):\n",
        "    filename = 'Desktop/ai/datasets/cifar-10-batches-py/data_batch_' + str(i)\n",
        "    open_data = unpickle(filename)\n",
        "    if len(data) > 0:\n",
        "        data = np.vstack((data, open_data['data']))\n",
        "        labels = np.hstack((labels, open_data['labels']))\n",
        "    else:\n",
        "        data = open_data['data']\n",
        "        labels = open_data['labels']\n",
        "\n",
        "data = grayscale(data)\n",
        "x = np.matrix(data)\n",
        "y = np.array(labels)\n",
        "print(x.shape)\n",
        "(50000, 1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXTUlJtF3uN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse_i = np.where(y == 7)[0]\n",
        "horse_x = x[horse_i]#selecting only horse class\n",
        "print(np.shape(horse_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gazCmpI4d6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Parameters\n",
        "n_inputs = 32 * 32\n",
        "BATCH_SIZE = 1\n",
        "batch_size = tf.placeholder(tf.int64)\n",
        "\n",
        "# using a placeholder\n",
        "x = tf.placeholder(tf.float32, shape=[None,n_inputs])\n",
        "## Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x).repeat().batch(batch_size)\n",
        "iter = dataset.make_initializable_iterator() # create the iterator\n",
        "features = iter.get_next()\n",
        "\n",
        "## Print the image\n",
        "with tf.Session() as sess:\n",
        "    # feed the placeholder with data\n",
        "    sess.run(iter.initializer, feed_dict={x: horse_x,\n",
        "                                         batch_size: BATCH_SIZE}) \n",
        "    print(sess.run(features).shape) \n",
        "    \n",
        "    plot_image(sess.run(features), shape=[32, 32], cmap = \"Greys_r\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw1Fj30UUBKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60_szShTWwMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial #to set predefined parameters for a function https://www.learnpython.org/en/Partial_functions\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjDqv2lUlFrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Encoder\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 150  # codings\n",
        "\n",
        "## Decoder\n",
        "n_hidden_3 = n_hidden_1\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.01\n",
        "l2_reg = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2lhL_FElGYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_layer = partial(tf.layers.dense,\n",
        "                         activation=tf.nn.elu,\n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         kernel_regularizer=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4qAejNHl1pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_1 = dense_layer(features, n_hidden_1)\n",
        "hidden_2 = dense_layer(hidden_1, n_hidden_2)\n",
        "hidden_3 = dense_layer(hidden_2, n_hidden_3)\n",
        "outputs = dense_layer(hidden_3, n_outputs, activation=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgDWpi35m45W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Optimize\n",
        "loss = tf.reduce_mean(tf.square(outputs - features))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "train  = optimizer.minimize(loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKZXfcZnrmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 150\n",
        "### Number of batches :  length dataset / batch size\n",
        "n_batches = horse_x.shape[0] // BATCH_SIZE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giXII7qZoQv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 100\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # initialise iterator with train data\n",
        "    sess.run(iter.initializer, feed_dict={x: horse_x,\n",
        "                                          batch_size: BATCH_SIZE})\n",
        "    print('Training...')\n",
        "    print(sess.run(features).shape) \n",
        "    for epoch in range(n_epochs):       \n",
        "        for iteration in range(n_batches):\n",
        "            sess.run(train)\n",
        "        if epoch % 10 == 0:\n",
        "            loss_train = loss.eval()   # not shown\n",
        "            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train) \n",
        "        #saver.save(sess, \"./my_model_all_layers.ckpt\") \n",
        "    save_path = saver.save(sess, \"model.ckpt\")    \n",
        "    print(\"Model saved in path: %s\" % save_path)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IvFZMWprNkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing the image\n",
        "test_data = unpickle('Desktop/ai/datasets/cifar-10-batches-py/test_batch')\n",
        "test_x = grayscale(test_data['data'])\n",
        "#test_labels = np.array(test_data['labels'])\n",
        "x_test=test_x[13]\n",
        "plot_image(x_test)\n",
        "x_test_1 = x_test.reshape((1, 32*32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr4Ccj4GsCdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:     \n",
        "        sess.run(tf.global_variables_initializer()) \n",
        "        sess.run(iter.initializer, feed_dict={x: x_test_1,\n",
        "                                      batch_size: 1})\n",
        "    ## Part 3:  Print the real and reconstructed image\n",
        "      # Restore variables from disk.\n",
        "        saver.restore(sess, \"model.ckpt\")  \n",
        "        print(\"Model restored.\")\n",
        "      # Reconstruct image\n",
        "        outputs_val = outputs.eval()\n",
        "        fig = plt.figure()\n",
        "      # Plot real\n",
        "        ax1 = fig.add_subplot(121)\n",
        "        plot_image(x_test_1, shape=[32, 32], cmap = \"Greys_r\")\n",
        "      # Plot estimated\n",
        "        ax2 = fig.add_subplot(122)\n",
        "        plot_image(outputs_val, shape=[32, 32], cmap = \"Greys_r\")\n",
        "        plt.tight_layout()\n",
        "        fig = plt.gcf()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}